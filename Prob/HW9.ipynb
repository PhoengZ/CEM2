{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Unizl2CVEfhI"
      },
      "source": [
        "# Attention !!!\n",
        "- Please write or take a screenshot of all answers in the pdf file. You won't be graded if there is no pdf file in the submission.\n",
        "- Only TODO 1, 2, 3, 4, 5, 6, 10, 11 will be graded.\n",
        "- **Extra credit:** 1% of total grade for Com Eng Math 2 for TODO 7, 8, 9 (1/3 each.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pMqXdYpngMzX"
      },
      "source": [
        "# Sampling\n",
        "\n",
        "Sampling is a process that is very important for writing simulations. In this section, you will try to sample from some common distributions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1IDhzu0KVO5t"
      },
      "source": [
        "TODO#1: Write functions that samples from the following distribution\n",
        "1. $\\mathcal{N}(0,1)$\n",
        "2. $Bernoulli(0.3)$\n",
        "3. $B(10, 0.3)$\n",
        "4. $Multinomial(n=10, p=[0.3,0.2,0.5])$\n",
        "5. $U(0,1)$\n",
        "<!-- 6. $T(0,1)$; $T(a,b)$ is defined as a function with a shape of a triangle that pass through point $(a,0)$, $(b,0)$, and $(b, K):\\frac{(b-a)K}{2}=1$. -->\n",
        "6. $T(0,1)$; $T(a,b)$ is defined as a function with a shape of a triangle that pass through point $(a,0)$, $(b,0)$, and $(\\frac{a+b}{2}, K):\\frac{(b-a)K}{2}=1$.\n",
        "\n",
        "Capture screenshot of the histogram for each of the distribution and paste them on the pdf file. The example is shown below.\n",
        "\n",
        "Hint: see scipy.stats for common distributions.\n",
        "[plt.hist](https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.hist.html) should be helpful for plotting histograms"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zU6rYTAnmeTg"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import norm, bernoulli, binom, multinomial, uniform, expon, triang\n",
        "\n",
        "\n",
        "def sample_normal(sample_size=10, mu=0, std=1):\n",
        "  sample = norm.rvs(size=sample_size,loc=mu, scale=std)\n",
        "  return sample\n",
        "\n",
        "\n",
        "def sample_bernoulli(sample_size=10, p=0.3):\n",
        "  sample = bernoulli.rvs(size=sample_size, p=p)\n",
        "  return sample\n",
        "\n",
        "\n",
        "def sample_binomial(sample_size=10, n=10, p=0.3):\n",
        "  sample = binom.rvs(size=sample_size, n=n, p=p)\n",
        "  return sample\n",
        "\n",
        "\n",
        "def sample_multinomial(sample_size=10, n=100, p=[0.3, 0.2, 0.5]):\n",
        "  sample = multinomial.rvs(size=sample_size, n=n, p=p)\n",
        "  return sample\n",
        "\n",
        "def sample_uniform(sample_size=10, from_x=0, to_x=1):\n",
        "  sample = uniform.rvs(size=sample_size, loc=from_x,scale=to_x-from_x)\n",
        "  return sample\n",
        "# loc is started point, scale is scaling value to end point\n",
        "def sample_triangle(sample_size=10, a=0, b=1):\n",
        "  # c argument is x at peak value and from formula (b-a)*k = 2 it's lead k equal 2, it's mean peak value is k\n",
        "  c = 0.5\n",
        "  sample = triang.rvs(size=sample_size, loc=a, scale=b-a, c=c)\n",
        "  return sample"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Histohgram of normal distribution\n",
        "sample = sample_normal()\n",
        "plt.hist(sample, density=True, bins=3)\n",
        "plt.title('Normal Distribution (n=10)')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "33AGODGg22VH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bernul = sample_bernoulli()\n",
        "plt.hist(bernul, density=True, bins=100, alpha=0.6)\n",
        "plt.title(\"Bernouli distributed with p = 0.3\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "i6xyyoLh8A8S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "binomail_sample = sample_binomial()\n",
        "plt.hist(binomail_sample, density=True, bins=3, alpha=0.6)\n",
        "plt.title(\"Binomail distribution with sample n = 10 and p= 0.3\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "aLMTQuq_C2ud"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "multimodel = sample_multinomial()\n",
        "plt.hist(multimodel, density=True, bins=10, alpha=0.6)\n",
        "plt.title(\"Multinomial distribution with n = 100 and p = [0.3, 0.2, 0.5]\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "S1GjRYMmC2Xb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "uni = sample_uniform()\n",
        "plt.hist(uni, density=True, bins=3, alpha=0.6)\n",
        "plt.title(\"Uniform with start from 0 to 1\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "vZFZrCguE5hc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "triangle_sample = sample_triangle()\n",
        "plt.hist(x=triangle_sample, density=True, bins=3, alpha=0.6)\n",
        "plt.title(\"Triangle distribution with n = 100 and start from 0 to 1 with peak value is 2\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "zxxvZuBGIqQ-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zxm0sZtKvMei"
      },
      "source": [
        "# Law of large number\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u7NrahI5q_nN"
      },
      "source": [
        "### Law of large number"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "76634yTWBz65"
      },
      "source": [
        "**TODO#2:** Using a sampling function from TODO#1.1, Plot the graph that shows the relation between an empirical mean and sampling size from 1 up to 10000.\n",
        "What does the graph imply about the difference between the empirical mean and the theoritical mean?"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "sampling_sizes = np.array([k*10 for k in range(1,10)]+[j*100 for j in range(1,10)]+[i*1000 for i in range(1,11)])\n",
        "# print(sampling_sizes)\n",
        "means = [sum(sample_normal(sample_size=s))/s for s in sampling_sizes]\n",
        "# print(means)\n",
        "plt.plot(sampling_sizes, means, 'o-')\n",
        "plt.axhline(y=0, color='r', linestyle='--')\n",
        "plt.xlabel(\"Sampling size\")\n",
        "plt.ylabel(\"Mean\")\n",
        "plt.title(\"relation when sampling size is increasing\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "DeqrMe4Pif8o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cuBPgENdq6GI"
      },
      "source": [
        "### Law of large number for histogram"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "au_DmcJ9O8Zu"
      },
      "source": [
        "The histogram is used to approximate the PDF of an unknown distribution.\n",
        "The bin in the histogram represents the frequency of the event happening inside the bin range.\n",
        "\n",
        "**TODO#3:** Given a fix bin number of 40. Plot the histogram of the data sampling from the function, `sample_normal(n, 0, 1)`, for different sizes of sample: 500, 1k, 5k and 10k.\n",
        "Compare and explain the relation between the approximation given by the histogram and the true PDF for each of the sample size."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample_500 = sample_normal(sample_size=500)\n",
        "sample_1k = sample_normal(sample_size=1000)\n",
        "sample_5k = sample_normal(sample_size=5000)\n",
        "sample_10k = sample_normal(sample_size=10000)\n",
        "samples = [sample_500, sample_1k, sample_5k, sample_10k]\n",
        "sizes  = ['500','1k','5k','10k']\n",
        "x_pdf = np.linspace(-4, 4, 100)\n",
        "y_pdf = norm.pdf(x_pdf, 0, 1)\n",
        "# second argument is mean value, and the last is standard derivation\n",
        "\n",
        "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
        "axes = axes.flatten()\n",
        "for i in range(len(samples)):\n",
        "    ax = axes[i]\n",
        "    sample_data = samples[i]\n",
        "    title = sizes[i]\n",
        "\n",
        "    ax.hist(sample_data, density=True, bins=40, alpha=0.7, label='Histogram (Sample)')\n",
        "\n",
        "    ax.plot(x_pdf, y_pdf, 'r--', linewidth=2, label='True PDF N(0,1)')\n",
        "\n",
        "    ax.set_title(title)\n",
        "    ax.set_xlabel('Value')\n",
        "    ax.set_ylabel('Density')\n",
        "    ax.legend()\n",
        "\n",
        "plt.suptitle('Histogram Approximation vs True PDF (bins=40)', fontsize=16)\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# จากกราฟจะเห็นว่า ยิ่ง sample size มากขึ้นเรื่อยๆความแม่นยำก็ยิ่งมากขึ้นเรื่อยๆ โดยเฉพาะ 10k จะเห็นว่า มีความคล้ายคลึงกับ Normal distribution แบบ Ideal มากๆ\n",
        "# โดยเฉพาะตอน sample size = 500 จะเห็นว่า histrogram จะมีความดีดมากๆ และ ขรุขระ มาก แต่เมื่อเพิ้ม sample size ความขรุขระ จะลดลงเรื่อยๆ"
      ],
      "metadata": {
        "id": "HuaWfMNmm73E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uBSjTKyqvOuK"
      },
      "source": [
        "## Central limit theorem"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E7YV2It_EM_m"
      },
      "source": [
        "In this part we will use the Central Limit Theorem to approximate the true probabity of getting more than 40 heads when an unfair coin, with the probability 0.3 of being head, is tossed 100 times.\n",
        "\n",
        "\n",
        "**TODO#4:** Simulate multiple coin tosses to construct a histrogram from the outcomes. Plot the histogram. Hint: x-axis should represents the number of heads when the coin is tossed 100 times. Does this histogram looks like a normal distribution?"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n = 100\n",
        "p = 0.3\n",
        "# we will use sample_binomail to create distrition of tossed coin with p = 0.3 and 100\n",
        "# assume sample_size considered high value because it easy to see what kind of distribtion it is.\n",
        "sample_tosses = sample_binomial(sample_size=10000,n=n, p=p)\n",
        "# sample ในแต่ละครั้งก็คือจำนวนหัวที่เกิดขึ้นในแต่ละ n ทำให้เข้าสู่สูตร Sn = X1 + X2 + .. + Xn ใน CLT\n",
        "x_normal = np.linspace(10,50,100)\n",
        "# mean of binomial distribution is n*p and standard derivation is sqrt(np*(1-p))\n",
        "y_normal = norm.pdf(x_normal, n*p, np.sqrt(n*p*(1-p)))\n",
        "plt.hist(sample_tosses, bins=40, density=True, alpha=0.6, label=\"Histrogram\")\n",
        "plt.plot(x_normal, y_normal, 'r--', linewidth=2, label=\"normal distribution with u=30, standard=21\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "# จากภาพจะเห็นว่า Histrogram จะมีความเหมือน Normal distribtion เป็นอย่างมาก\n",
        "# โดยค่า P จะเปลี่ยนรูปแบบการกระจายของกราฟทำให้ค่าเบ้ขวาแต่เมื่อ n มากๆมันจะทำให้\n",
        "# ผลลัพธ์ของการเบ้ จะหายไปเพราะค่าจากทั้งสองฝั่งมันมีค่ามาก"
      ],
      "metadata": {
        "id": "RWv83kd2lXCR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uuziwG81nfe9"
      },
      "source": [
        "**TODO#5:** Use CLT to find the probability of getting more than 40 heads.\n",
        "\n",
        "**TODO#6:** Compare and find the difference between CLT's approximation and the actual probability using the binomial distribution."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ข้อ 5\n",
        "# เราจะใช้การเปิดตาราง Z เพราะว่าเราได้ว่ากราฟมีความเป็น normal distribution (ถ้าทำมือ)\n",
        "# แต่ scipy.stat สามารถ หา cdf จาก method cdf ได้ เช่น norm.cdf\n",
        "\n",
        "u = n*p\n",
        "s = round(np.sqrt(n*p*(1-p)),4)\n",
        "z_value = (40.5-u)/s\n",
        "# ใช้ 40.5 เพราะเรามองว่า Area ของ >= 41 คือเริ่มตั้งแต่ 40.5 เพราะแต่ละค่าที่เป็น distribut กว้าง 1\n",
        "# print(z_value)\n",
        "prob_from_left = norm.cdf(z_value)\n",
        "prob_gte_41 = 1-prob_from_left\n",
        "print(round(prob_gte_41,4))"
      ],
      "metadata": {
        "id": "UkmNSgpdlIoi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ข้อ 6\n",
        "prob_le_40 = binom.cdf(k=40, n=n, p=p)\n",
        "prob_gt_40 = 1 - prob_le_40\n",
        "print(round(prob_gt_40,4))\n",
        "# จะเห็นว่าค่าที่ได้ใกล้เคียงกับ CDF โดยใช้ normal distribton มากๆ"
      ],
      "metadata": {
        "id": "zDZvYlmYuTrM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NjIN-y36Hzj2"
      },
      "source": [
        "# Algebra of Random Variables"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Ff4_Pi9XXnP"
      },
      "source": [
        "Given an independent random variable $X$ and $Y$, such that $X \\sim F$ and $Y \\sim U(3,5)$. The summation of those two is written as $Z = X + Y$ and the PDF of $F$ is defined below.\n",
        "$$\n",
        "F(X) =\n",
        "\\begin{cases}\n",
        "0.1, & -2<=X<=0\\\\\n",
        "0.4, & 0<X<=2 \\\\\n",
        "\\end{cases}\n",
        "$$\n",
        "**TODO#7:** Find $P( 3 < Z < 5 )$."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.integrate import quad\n",
        "def fx(x):\n",
        "  if -2 <= x and x <= 0:\n",
        "    return 0.1\n",
        "  if 0 < x and x <= 2:\n",
        "    return 0.4\n",
        "  return 0\n",
        "def fy(y):\n",
        "  if y < 3 or y > 5:\n",
        "    return 0\n",
        "  return 1/2\n",
        "\n",
        "def intergrate_z(x,z):\n",
        "  return fx(x)*fy(z-x)\n",
        "\n",
        "def fz(z):\n",
        "  result = quad(func=intergrate_z, a=-np.inf,b=np.inf,args=(z,))\n",
        "  # argument a, b จะป้อนเข้า intergrateeที่ parameter ตัวแรกโดยอัตโนมัติ แต่ args(z,) เป็นการบอกว่า parameter ตัวที่สอง ให้ป้อนค่า z เข้าไป\n",
        "  return result[0]\n",
        "prob = quad(func=fz, a=3,b=5)\n",
        "print(f\"ความน่าจะเป็น P(3 < Z < 5) คือ: {prob[0]:.4f}\")\n",
        "# ใช้หลัการ sum of random variables ที่ใช้งาน Convolution ของสอง fx และ fy\n",
        "# fx+y(z) = (fx * fy)(z)\n",
        "# ชวงแรก z < 1 มีค่าเท่ากับ 0 เพราะไม่ทับกัน\n",
        "# ช่วงสอง 1 <= z < 3\n",
        "# ช่วงสาม 3 <= z < 5\n",
        "# ช่วง 4 z>=5"
      ],
      "metadata": {
        "id": "DsNBdD71x_0m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i9OpVCQ_vLvR"
      },
      "source": [
        "# Correlation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JuwXaTlQkzvd"
      },
      "source": [
        "The correlation captures the linear relationshi between two sets of random variables. The higher magnitude of the correlation indicates a stronger relationship.\n",
        "\n",
        "\n",
        "**TODO#8:** Find the correlation of $X$ and $Y = X + A$, given that $X \\sim U(-1,1)$ and\n",
        "1. $A = 10$\n",
        "2. $A \\sim U(-1,1)$\n",
        "3. $A \\sim U(-10,10)$\n",
        "4. $A \\sim U(-100,100)$\n",
        "\n",
        "\n",
        "**TODO#9:** From the results in TODO#8, answer following questions\n",
        "1. Does the correlation decrease as we increase the randomness of A ?\n",
        "2. Explain the result when we change from $A \\sim U(-10,10)$ to $A \\sim U(9090,10010)$. Hint: Compare the result with $A$ and $A + 10000: A \\sim U(-10,10) $"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ข้อ 8\n",
        "# correlation = Cov(x,y)/sqrt(var(x)*var(y))\n",
        "size = 1000\n",
        "x = sample_uniform(sample_size=size, from_x=-1,to_x=1)\n",
        "a1 = sample_uniform(sample_size=size, from_x=-1,to_x=1)\n",
        "a2 = sample_uniform(sample_size=size, from_x=-10,to_x=10)\n",
        "a3 = sample_uniform(sample_size=size, from_x=-100,to_x=100)\n",
        "\n",
        "y1 = x + 10\n",
        "correlation_1 = np.corrcoef(x,y1)\n",
        "# print(correlation)\n",
        "# [[pxx, pxy],[pyx,pyy]]\n",
        "print(correlation_1[0,1])\n",
        "\n",
        "y2 = x+a1\n",
        "correlation_2 = np.corrcoef(x,y2)\n",
        "print(correlation_2[0,1])\n",
        "\n",
        "y3 = x+a2\n",
        "correlation_3 = np.corrcoef(x,y3)\n",
        "print(correlation_3[0,1])\n",
        "\n",
        "y4 = x+a3\n",
        "correlation_4 = np.corrcoef(x,y4)\n",
        "print(correlation_4[0,1])"
      ],
      "metadata": {
        "id": "M9FOv6ehyAp0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ข้อ 9\n",
        "print(f'9.1 ตอบ ใช่')\n",
        "\n",
        "y5 = x + 10000\n",
        "correlation_5 = np.corrcoef(x,y5)\n",
        "print(f'correlation ของ x+ 10000: {correlation_5[0,1]}')\n",
        "print(f'correlation ของ x+ U(-10,10): {correlation_3[0,1]}')\n",
        "\n",
        "y6 = y5 + a2\n",
        "correlation_6 = np.corrcoef(x,y6)\n",
        "print(f'correlation ของ x+ U(-10,10) + 10000: {correlation_6[0,1]}')\n",
        "print('จะเห็นว่า correlation ของ x+U(-10,10) กับ x+ U(-10,10) + 10000 แทบไม่ต่างกันเพราะค่าคงที่แทบจะไม่ส่งผลกับCorrelation')\n",
        "print('อีกทั้งค่าคงทีทำหน้าที่เพียงแค่ shift ค่าออกไปแต่ไม่ได้ส่งผลต่อ Variance และ Covariance ทำให้ correlation ไม่เปลี่ยนแปลงมาก')"
      ],
      "metadata": {
        "id": "ZxLt5o7YvbKd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o1DRnpiEu7US"
      },
      "source": [
        "# Hamtaro and his cloud storage empire.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IBaF48SEIO9X"
      },
      "source": [
        "After the success in the manufacturing business. Hamtaro wants to expand his business into a new sector.\n",
        "Since cloud computing is currently booming, he decides to enter into the cloud storage business.\n",
        "\n",
        "The storage disk that Hamtaro uses can operate only in the temperature of $[0,30]$ degree Celcius. The disk has the prabability of a read failure $P(Fail|t) = \\frac{0.97}{2250}(t-15)^2+0.001$ where $t$ is the operating temperature.\n",
        "<!-- Hamtaro's disks has a special architecture that can be  simultaneously read by infinite requests at the same time. However, a failure of one request will cause all of its parallels to fail. -->\n",
        "\n",
        "Since Hamtoro doesn't want any failures in his service, he decides to buy a super luxury air-conditioning system to control the temperature in his data warehouse. Even if the air conditioner is extremely expensive, the room temperature is still not stable. When Hamtaro tries to set the tempurature to $\\mu$, the actual temperature is random and can be modeled by $t\\sim U(\\mu-1,\\mu+1)$.\n",
        "\n",
        "**TODO#10:** Answer the following questions.\n",
        "1. What is the temperature that Hamtaro should set the air conditioner to? Justify your answer.\n",
        "2. What is the probability of failure at the temperature used in part 1?\n",
        "<!-- 3. If Hamtaro want to handle 10k concurrent requests, what is the minimum disks should Hamtoro has to make 99.99% of disk availability and how should he split the workloads? Hamtaro connects the all the disks in parallel. The read request will fail if all disks fail to be read at the same time. -->\n",
        "3. What is the minimum number of disks that Hamtoro has to use to make sure that the probability of having more than 1 failure in 10k requests is less than 0.01\\%? Hamtaro connects the all the disks in parallel. The read request will fail if all disks fail to at the same time.\n",
        "4. **Extra** The temperature is now modeled by $t\\sim \\mathcal{N}(\\mu,9)$ instead of $t\\sim U(\\mu-1,\\mu+1)$. Repeat question 1-3.\n",
        "\n",
        "**Hint:** `scipy.integrate.quad` can help you do integration."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ข้อ 1 ตอบ u = 15 เพราะ จะทำให้ t มีค่าเฉลี่ยเท่ากับ 15 ซึ่งทำให้ term แรกของ P มีค่าเป็น 0 ทำให้ P มีค่า 0.001\n",
        "print('ข้อ 1. ตอบ u = 15 เพราะ จะทำให้ t มีค่าเฉลี่ยเท่ากับ 15 ซึ่งทำให้ term แรกของ P มีค่าเป็น 0 ทำให้ P มีค่า 0.001')\n",
        "# ข้อ 2 หา expected value ที่จะ fail โดยใช้ intergrate(fn*gn)\n",
        "from scipy.integrate import quad\n",
        "def fn(x):\n",
        "    return ((0.97/2250)*(x-15)**2 + 0.001)*0.5\n",
        "\n",
        "p = quad(a=14,b=16,func=fn)\n",
        "print(f'ข้อ 2. ตอบ มีความน่าจะเป็นที่จะ Fail เท่ากับ: {round(p[0],4)}')\n"
      ],
      "metadata": {
        "id": "rCYUHHXgKJ-7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ข้อ 3 จาก all disk failur at the same time ถึงจะ read fail จะได้ว่า p = p^N โดย n คือจำนววน disk ที่กำลังหา\n",
        "# ให้ n = 10000 คือจำนวน request ที่เข้ามา\n",
        "idx = 1\n",
        "result = 0\n",
        "while(True):\n",
        "  pi = p[0]**idx\n",
        "  idx+=1\n",
        "  at_least_fail = binom.cdf(1, 10000,pi)\n",
        "  # argument แรกคือค่าที่จะสำเร็จ 1 ครั้งคือมี fail 1 ครั้ง\n",
        "  check = 1 - at_least_fail\n",
        "  if (check < 0.0001):\n",
        "    # < 0.01% = 0.0001\n",
        "    result = check\n",
        "    break\n",
        "print(f'จำนวน disk ที่ต้องใช้คืดเป็นจำนวน {idx}')\n",
        "print(f'ข้อ 3. ตอบ มีความน่าจะเป็นที่จะ Fail เท่ากับ: {round(result,6)}')"
      ],
      "metadata": {
        "id": "rnIh9Us6aTpC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ข้อ 4.\n",
        "# ข้อ 4.1 ให้ u = 15 เพราะ probability ที่ u = 15 มีค่าสูงที่สุด\n",
        "print('ข้อ 4.1. ตอบ u = 15 เพราะ จะทำให้ t มีค่าเฉลี่ยเท่ากับ 15 ซึ่งทำให้ term แรกของ P มีค่าเป็น 0 ทำให้ P มีค่า 0.001 อีกทั้งโอกาสที่ t = 15 มีค่าสูงที่สูงที่สุดจาก normal distribution')\n",
        "# ข้อ 4.2\n",
        "x = np.linspace(10,30,100)\n",
        "# gn = norm.pdf(x,15,9)\n",
        "# plt.plot(x,gn, 'r--', linewidth=2)\n",
        "def gn(x):\n",
        "  return norm.pdf(x,15,3)\n",
        "def fn_1(x):\n",
        "  return ((0.97/2250)*(x-15)**2 + 0.001)*gn(x)\n",
        "p = quad(func=fn_1, a=10,b=30)\n",
        "print(f'ข้อ 4.2. ตอบ มีความน่าจะเป็นที่จะ Fail เท่ากับ: {round(p[0],6)}')"
      ],
      "metadata": {
        "id": "IBe5ZdJzbew2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ข้อ 4.3\n",
        "idx = 1\n",
        "result = 0\n",
        "while(True):\n",
        "  pi = p[0]**idx\n",
        "  idx+=1\n",
        "  at_least_fail = binom.cdf(1,10000,pi)\n",
        "  check = 1 - at_least_fail\n",
        "  if (check < 0.0001):\n",
        "    result = check\n",
        "    break\n",
        "print(f'ข้อ 4.3. ตอบ มีความน่าจะเป็นที่จะ Fail เท่ากับ: {round(result,7)}')\n",
        "print(f'จำนวน disk ที่ต้องใช้คืดเป็นจำนวน {idx}')"
      ],
      "metadata": {
        "id": "Dt4VK8XpjVPW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YWQenJlPnGIN"
      },
      "source": [
        "# Moontaro\n",
        "![picture](https://i.redd.it/mcveltqx2j071.png)\n",
        "\n",
        "Recently, cryptocurrency investment has become extremely popular due to its extraordinarily high rates of return. Though many people consider it a risky investment, Hamtaro does not want to miss this opportunity and start gathering information about these coins. His research suggests that four coins, namely $a$, $b$, $c$, and $d$, have a promising future to go to the moon.\n",
        "\n",
        "\n",
        "Hamtaro wants to run simulations to validate his chances. As the value of the coins is non-deterministic, he models it sequentially based on their historical values (a.k.a. autoregressive model). The price of coin $i$ at day $t$ is formulated as\n",
        "\n",
        "$p_{i,t} = p_{i,t-1} \\times r_{i,t}$, where $i \\in \\{a, b, c, d\\}$, and  $p_{i, 0} = 10$.\n",
        "\n",
        "The rates $r_{i,t}$, are drawn from a multivariant guassian distribution $\\mathcal{N}(\\mathbf{\\mu}, \\mathbf{\\Sigma})$, where $\\mu = [1.003, 1.002, 1.004, 1.004]^T$ and $\\mathbf{\\Sigma}$ as given below:\n",
        "\n",
        "$\\mathbf{\\Sigma}$ | a | b | c | d\n",
        "--- | --- | --- | --- |---\n",
        "a |  10 x 10$^{-3}$ | 0 | 4 x 10$^{-3}$ | 5 x 10$^{-3}$\n",
        "b |  0  | 3 x 10$^{-3}$ | 0 | 0\n",
        "c |  4 x 10$^{-3}$  | 0 | 12 x 10$^{-3}$| 2 x 10$^{-3}$\n",
        "d |  5 x 10$^{-3}$  | 0 | 2 x 10$^{-3}$ | 15 x 10$^{-3}$\n",
        "\n",
        "\n",
        "<!-- 1. Are $p_{a,t}$ and $p_{b,t}$ independent ? Why ?\n",
        "2. Are $p_{a,t}$ and $p_{c,t}$ independent ? Why ?\n",
        "3. Are $p_{a,t}$ and $p_{d,t}$ independent ? Why ? -->\n",
        "\n",
        "**TODO11:**\n",
        "1. Which pairs of coins are independent? Why?\n",
        "2. Given the following definitions:\n",
        "  - <b>Return</b> :  a coin price at day $T$ minus the price at day 0, i.e., the return of coin $i$ at day $T = p_{i,T} - p_{i, 0}$.\n",
        "  - <b>Expected return</b> : the average return from 10000 distinct simulated end prices.\n",
        "  \n",
        "  Simulate the expected return for each coin if Hamtaro wants to sell his coins 30 and 180 days after buying $(T \\in \\{30, 180\\})$.\n",
        "  hint: you should write reusable functions to make your life easier.\n",
        "3. Which coin has the highest probability of having profit (end price is higher than start price)? Compare the variance of the return with other coins.\n",
        "4. How can the expected return be positive while having around 50\\% chance of profitability?\n",
        "\n",
        "After simulating the price of individual coins, Hamtaro now proposes seven investment strategies (portfolio) to maximize the profit. The detail of each strategy is shown in the table below.  \n",
        "**ขายหลังจาก 30 วัน**\n",
        "Strategy | Buy $a$ | Buy $b$ | Buy $c$ | Buy $d$ | Expected\\[return\\] | Variance\\[return\\] | Probability of having profit\n",
        "---| --- |--- |--- | ---| --- | --- | ---\n",
        "1  | 100% | 0%   | 0%  |    0%| 0.8621995485655338 | 39.12259119722992 |0.4541\n",
        "2  | 0%   | 100% | 0%  |    0%| 0.5726676487150836 | 10.344334112191925|0.5148\n",
        "3  | 0%   | 0%   | 100%|    0%| 1.2119389069946793 | 53.09450250167658 |0.4616\n",
        "4  | 0%   | 0%   |   0%|  100%| 1.260326763097639  | 72.81678658150535 |0.4421\n",
        "5  | 50%  | 50%  | 0%  |    0%| 0.7174335986403086 | 12.306824623890858|0.5149\n",
        "6  | 50%  | 0%   | 50% |    0%| 1.0370692277801066 | 30.60093470757088 |0.4911\n",
        "7  | 50%  | 0%   |  0% |   50%| 1.0612631558315866 | 37.54445050073845 |0.4751\n",
        "------------------------------------------------------------------\n",
        "\n",
        "5. Fill the empty values in the table (both $T = 30, 180$).\n",
        "6. Which strategy yields the highest return?\n",
        "7. Which strategy is the safest one?\n",
        "8. Compare the variances between the stategy 6 and 7. What happens, and why is this the case? **Hint:** Consider cov($r_a$, $r_c$) and cov($r_a$, $r_d$).\n",
        "9. From the problems above, come up with a general practice for good investment? Please also state your reasoning. You can include additional simulations to support the argument."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YmBGwH9ZzrEH"
      },
      "source": [
        "# จาก sigma ที่ให้มา (covariance matrix)\n",
        "print(f'ข้อ 1 ตอบ จะเห็นว่า cov(b,a), cov(b,c), cov(b,d) มีค่าเท่ากับ 0 ทำใหั้ correlation เป็น 0 ด้วยทำให้เป็นเหรียญที่ Independent กับเหรียญอื่น')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ข้อ 2\n",
        "import numpy as np\n",
        "from scipy.stats import multivariate_normal\n",
        "\n",
        "coin_name = ['a', 'b', 'c', 'd']\n",
        "init_prices = np.array([10, 10, 10, 10]) # ตั้งราคาเหรีญเริ่มต้นไว้ที่ 10\n",
        "\n",
        "rate_mean = np.array([ 1.003, 1.002, 1.004, 1.004])\n",
        "rate_cov  = np.array([\n",
        "                [10, 0, 4, 5],\n",
        "                [ 0, 3, 0, 0],\n",
        "                [ 4, 0,12, 2],\n",
        "                [ 5, 0, 2,15],\n",
        "])/1000\n",
        "\n",
        "def get_profit_prob(coin):\n",
        "  s = np.sum(coin > 0)/len(coin)\n",
        "  return s\n",
        "def get_rate():\n",
        "  rates = multivariate_normal.rvs(rate_mean, rate_cov, size=1)\n",
        "  # สุ่มสี่ค่าออกมาโดยอิงตาม covariance\n",
        "  m = np.maximum(0, rates) # ป้องกัน rate ติดลบ\n",
        "  return m\n",
        "def get_coin_price(prev_price):\n",
        "  today_rates = get_rate() # สุ่ม rate ของวันนี้\n",
        "  return prev_price * today_rates, today_rates\n",
        "def get_return(prices, day):\n",
        "  return prices[:, day] - prices[:, 0]\n",
        "def get_expected_return(days, lab):\n",
        "  # ndays คือจำนวนวันที่จำลอง\n",
        "  # ntrials คือจำนวนการทดลองที่จะทำ\n",
        "  N_coins = len(init_prices)\n",
        "  returns = np.zeros((N_coins, lab))\n",
        "  # จะได้ return ออกมา 4 row 10000 col เพื่อทำการเก็บผลลัพธ์ของแต่ละการทดลอง\n",
        "  # โดยแถวคือ เหรียญที่ i และ column คือการทดลองที่ j\n",
        "  for nt in range(lab):\n",
        "    # วนซ้ำ 10000 simulate ตามที่โจทย์ต้องการ\n",
        "    prices = np.zeros((N_coins, days + 1))\n",
        "    rates  = np.zeros((N_coins, days + 1))\n",
        "    prices[:,0] = init_prices\n",
        "    # กำหนดให้ column แรกเป็น price ในวันแรก\n",
        "    for t in range(1, days+1):\n",
        "      # วนซ้ำตั้งแต่วันที่ 1 ถึงวันที่กำหนดในที่นี้ก็จะมี 30,180 วัน\n",
        "      prices[:, t], rates[:, t] = get_coin_price(prices[:, t-1])\n",
        "\n",
        "    returns[:, nt] = get_return(prices, days)\n",
        "    # ผลลัพธ์ของวันท้ายเก็บค่าลงใน column ของการทดลองแต่ละครั้ง\n",
        "    # โดยเป็นไปตาม definition ของ Return\n",
        "  return returns"
      ],
      "metadata": {
        "id": "OV0TRF3c6O8u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "days_choices = [30, 180]\n",
        "answer = dict()\n",
        "count = 10000\n",
        "for day in days_choices:\n",
        "  answer[day] = get_expected_return(day, count)\n",
        "  print(f\"จำนวนวัน={day}\")\n",
        "  for i in range(len(coin_name)):\n",
        "    # วนลูปของแต่ละเหรียญของแต่ละช่วงเวลาที่กำหนด\n",
        "    coin_return = answer[day][i]\n",
        "    # นำค่าของแถว coin แต่ละแถวมาหาค่าทางสถิติ\n",
        "    print(f'{coin_name[i]}, มีexpected_return {round(np.mean(coin_return),4)}, มีความน่าจะเป็นเท่ากับ: {round(get_profit_prob(coin_return),4)}')"
      ],
      "metadata": {
        "id": "HXndx1_H71ce"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('ข้อ 3 ตอบ เหรียญ b มี probability ในการได้กำไรมากที่สุด')\n",
        "print('ข้อ 4 ตอบ เพราะแม้ความน่าจะเป็นจะต่ำกว่า 0.5 แต่มูลค่าที่เราได้กลับมาจากการลงทุน เมื่อชนะได้ 1 ครั้งมีมูลค่าสูงมากจนทำให้ Expected return value เป็นบวกได้')"
      ],
      "metadata": {
        "id": "YvctXuXZ850B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "strategy = np.array([\n",
        "              [1.0, 0.0, 0.0, 0.0],\n",
        "              [0.0, 1.0, 0.0, 0.0],\n",
        "              [0.0, 0.0, 1.0, 0.0],\n",
        "              [0.0, 0.0, 0.0, 1.0],\n",
        "              [0.5, 0.5, 0.0, 0.0],\n",
        "              [0.5, 0.0, 0.5, 0.0],\n",
        "              [0.5, 0.0, 0.0, 0.5],\n",
        "])"
      ],
      "metadata": {
        "id": "DxI8S9WFMGNv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ข้อ 5\n",
        "\n",
        "for d in [30, 180]:\n",
        "  ans = answer[d]\n",
        "  print(f\"days {d}\")\n",
        "  for s in strategy:\n",
        "    arr = np.array([s[i] * ans[i] for i in range(len(coin_name))])\n",
        "    # print(arr)\n",
        "    return_from_strategy = arr.sum(axis=0)\n",
        "    # ทำการคูณค่าที่ลงทุนไปในแต่ละเหรียญเข้ารกับ return ของ coin จากนั้นหาผลรวมของแต่ละ column จะได้ออกมาเป็น return ของแต่ละการ simulation\n",
        "    s_return = return_from_strategy.mean()\n",
        "    s_var = return_from_strategy.var()\n",
        "    s_probability = get_profit_prob(return_from_strategy)\n",
        "    # หาค่าทางสถิติต่างๆ\n",
        "    print(f'แผน:{s}, มี expected_return เป็น: {s_return}, มี variance เป็น: {s_var}, มีความน่าจะเป็น:{s_probability}')"
      ],
      "metadata": {
        "id": "GB1RyNhp8fId"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ขายหลังจาก 30 วัน**\n",
        "Strategy | Buy $a$ | Buy $b$ | Buy $c$ | Buy $d$ | Expected\\[return\\] | Variance\\[return\\] | Probability of having profit\n",
        "---| --- |--- |--- | ---| --- | --- | ---\n",
        "1  | 100% | 0%   | 0%  |    0%| 0.8621995485655338 | 39.12259119722992 |0.4541\n",
        "2  | 0%   | 100% | 0%  |    0%| 0.5726676487150836 | 10.344334112191925|0.5148\n",
        "3  | 0%   | 0%   | 100%|    0%| 1.2119389069946793 | 53.09450250167658 |0.4616\n",
        "4  | 0%   | 0%   |   0%|  100%| 1.260326763097639  | 72.81678658150535 |0.4421\n",
        "5  | 50%  | 50%  | 0%  |    0%| 0.7174335986403086 | 12.306824623890858|0.5149\n",
        "6  | 50%  | 0%   | 50% |    0%| 1.0370692277801066 | 30.60093470757088 |0.4911\n",
        "7  | 50%  | 0%   |  0% |   50%| 1.0612631558315866 | 37.54445050073845 |0.4751"
      ],
      "metadata": {
        "id": "DW6iYUvjeeJq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ขายหลังจาก 180 วัน**\n",
        "Strategy | Buy $a$ | Buy $b$ | Buy $c$ | Buy $d$ | Expected\\[return\\] | Variance\\[return\\] | Probability of having profit\n",
        "---| --- |--- |--- | ---| --- | --- | ---\n",
        "1  | 100% | 0%   | 0%  |    0%| 6.91871839169123 | 1194.6231569384317 |0.3995\n",
        "2  | 0%   | 100% | 0%  |    0%| 4.43329679272481 | 146.19787448389314 |0.5562\n",
        "3  | 0%   | 0%   | 100%|    0%| 10.274338152137293 | 2415.5765247381496 |0.4037\n",
        "4  | 0%   | 0%   |   0%|  100%| 10.376991155276293  | 2885.3938212818084 |0.3568\n",
        "5  | 50%  | 50%  | 0%  |    0%| 5.67600759220802 | 336.1190057658521 |0.5541\n",
        "6  | 50%  | 0%   | 50% |    0%| 8.596528271914261 | 1028.5312623442328 |0.4695\n",
        "7  | 50%  | 0%   |  0% |   50%| 8.647854773483763 | 1211.5234495111822 |0.4354"
      ],
      "metadata": {
        "id": "qMbNqR8LefEc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('ข้อ 6 ตอบ แผนที่ 4 ให้ผล expected_return ที่ดีสุดเมื่อขายเหรียญ 30 วัน และ 180 วัน')\n",
        "print('ข้อ 7 ตอบ แผนที่ 5 ให้ probability สูงสุดเมื่อขายหลัง 30 วันแต่ แผน 2 ให้ probability ดีสุดเมื่อขายหลังจาก 180 วัน')\n",
        "print('''ข้อ 8 ตอบ เนื่องจาก var(x,y) = var(x) + var(y) + 2*cov(x,y) ทำให้ยิ่ง cov มากยิ่งทำให้ var โดยจาก table ที่โจทย์กำหนดให้\n",
        "จะเห็นว่า Cov(a,d) มีค่ามากกว่า Cov(a,c) ทำให้ Var ของแผนที่ 7 มากกว่าแผนที่ 6''')\n",
        "print('ข้อ 9 ตอบ ใช้งาน Broker ถ้าคุณไม่เก่งไม่ก็ลงทุนสิ่งที่มีความเสี่ยงต่ำ แต่ถ้าอยากรวยไว้ก็ลงทุนแบบ All in')"
      ],
      "metadata": {
        "id": "1at3bLlp8pbl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3cTVvBu088Ue"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}